{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing multiple models with different levels of feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/enriccogemha/Developer/HousePriceRegressor/data\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = pathlib.Path.cwd() / 'data'\n",
    "print(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_path = DATA_DIR / 'processed' / 'ames_model_data.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(clean_data_path, 'rb') as file:\n",
    "    model_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2877 entries, 0 to 2929\n",
      "Columns: 165 entries, Lot.Frontage to Exterior_Other\n",
      "dtypes: bool(119), float64(34), int64(12)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "model_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to store the results for each model\n",
    "\n",
    "model_results = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_data.drop(columns=['SalePrice']).copy()\n",
    "y = model_data['SalePrice'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      Lot.Frontage  Lot.Area  Lot.Shape  Land.Slope  Overall.Qual  \\\n",
       " 0            141.0   31770.0          1           0             5   \n",
       " 1             80.0   11622.0          0           0             4   \n",
       " 2             81.0   14267.0          1           0             5   \n",
       " 3             93.0   11160.0          0           0             6   \n",
       " 4             74.0   13830.0          1           0             4   \n",
       " ...            ...       ...        ...         ...           ...   \n",
       " 2925          37.0    7937.0          1           0             5   \n",
       " 2926          68.0    8885.0          1           1             4   \n",
       " 2927          62.0   10441.0          0           0             4   \n",
       " 2928          77.0   10010.0          0           1             4   \n",
       " 2929          74.0    9627.0          0           1             6   \n",
       " \n",
       "       Overall.Cond  Mas.Vnr.Area  Exter.Qual  Exter.Cond  BsmtFin.SF.1  ...  \\\n",
       " 0                4         112.0           2           2         639.0  ...   \n",
       " 1                5           0.0           2           2         468.0  ...   \n",
       " 2                5         108.0           2           2         923.0  ...   \n",
       " 3                4           0.0           1           2        1065.0  ...   \n",
       " 4                4           0.0           2           2         791.0  ...   \n",
       " ...            ...           ...         ...         ...           ...  ...   \n",
       " 2925             5           0.0           2           2         819.0  ...   \n",
       " 2926             4           0.0           2           2         301.0  ...   \n",
       " 2927             4           0.0           2           2         337.0  ...   \n",
       " 2928             4           0.0           2           2        1071.0  ...   \n",
       " 2929             4          94.0           2           2         758.0  ...   \n",
       " \n",
       "       Exterior_BrkFace  Exterior_CemntBd  Exterior_HdBoard  Exterior_MetalSd  \\\n",
       " 0                 True             False             False             False   \n",
       " 1                False             False             False             False   \n",
       " 2                False             False             False             False   \n",
       " 3                 True             False             False             False   \n",
       " 4                False             False             False             False   \n",
       " ...                ...               ...               ...               ...   \n",
       " 2925             False             False              True             False   \n",
       " 2926             False             False              True             False   \n",
       " 2927             False             False              True             False   \n",
       " 2928             False             False              True             False   \n",
       " 2929             False             False              True             False   \n",
       " \n",
       "       Exterior_Plywood  Exterior_Stucco  Exterior_VinylSd  Exterior_Wd Sdng  \\\n",
       " 0                False            False             False             False   \n",
       " 1                False            False              True             False   \n",
       " 2                False            False             False              True   \n",
       " 3                False            False             False             False   \n",
       " 4                False            False              True             False   \n",
       " ...                ...              ...               ...               ...   \n",
       " 2925             False            False             False             False   \n",
       " 2926             False            False             False             False   \n",
       " 2927             False            False             False             False   \n",
       " 2928             False            False             False             False   \n",
       " 2929             False            False             False             False   \n",
       " \n",
       "       Exterior_WdShing  Exterior_Other  \n",
       " 0                False           False  \n",
       " 1                False           False  \n",
       " 2                False           False  \n",
       " 3                False           False  \n",
       " 4                False           False  \n",
       " ...                ...             ...  \n",
       " 2925             False           False  \n",
       " 2926             False           False  \n",
       " 2927             False           False  \n",
       " 2928             False           False  \n",
       " 2929             False           False  \n",
       " \n",
       " [2877 rows x 164 columns],\n",
       " 0       5.332438\n",
       " 1       5.021189\n",
       " 2       5.235528\n",
       " 3       5.387390\n",
       " 4       5.278525\n",
       "           ...   \n",
       " 2925    5.153815\n",
       " 2926    5.117271\n",
       " 2927    5.120574\n",
       " 2928    5.230449\n",
       " 2929    5.274158\n",
       " Name: SalePrice, Length: 2877, dtype: float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42  # Any number here, really."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.25,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2877, 164), (2157, 164), (720, 164))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Xtrain.shape, Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2877,), (2157,), (720,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiro teste: modelo linear com scaling e cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "float64_columns = Xtrain.select_dtypes('float64').columns\n",
    "\n",
    "col = ColumnTransformer(\n",
    "    [\n",
    "        ('scale', StandardScaler(), float64_columns),\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    ")\n",
    "\n",
    "col.fit(Xtrain)\n",
    "\n",
    "Xtrain_scaled = col.transform(Xtrain)\n",
    "Xtest_scaled = col.transform(Xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "grid = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'positive': [True, False],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    lr,\n",
    "    grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    return_train_score=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'fit_intercept': True, 'positive': True}\n",
      "Best score: -0.0031667526802596456\n",
      "Average error is 13.83%\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(Xtrain_scaled, ytrain)\n",
    "\n",
    "print(f'Best parameters: {grid_search.best_params_}')\n",
    "print(f'Best score: {grid_search.best_score_}')\n",
    "\n",
    "rmse = np.sqrt(-grid_search.best_score_)\n",
    "error_percent = 100 * (10**rmse - 1)\n",
    "print(f'Average error is {error_percent:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results['LinearRegression'] = round(error_percent, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos perceber que existe um erro menor para o modelo com cross-validation e scaling, portanto iremos adotar isso para o restante dos experimentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo experimento: Modelo Lasso com cross-validation e scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo Lasso, que significa \"Least Absolute Shrinkage and Selection Operator\" (Operador de Contração e Seleção Mínimas de Absoluto), é um método de regressão linear que inclui uma regularização L1. A regularização L1 envolve a adição de um termo de penalização à função objetivo da regressão, que incentiva a maioria dos coeficientes a serem exatamente iguais a zero. Isso torna o Lasso uma técnica eficaz para seleção de recursos e para lidar com problemas de regressão com alta dimensionalidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "grid = {\n",
    "    'alpha': np.logspace(-8, -3, 200),\n",
    "}\n",
    "\n",
    "lasso = Lasso(random_state=RANDOM_SEED)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    lasso,\n",
    "    grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    return_train_score=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 8.804883581643464e-05}\n",
      "Best score: -0.003296308851327881\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "grid_search.fit(Xtrain_scaled, ytrain)\n",
    "\n",
    "print(f'Best parameters: {grid_search.best_params_}')\n",
    "print(f'Best score: {grid_search.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error is 14.13%\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(-grid_search.best_score_)\n",
    "error_percent = 100 * (10**rmse - 1)\n",
    "print(f'Average error is {error_percent:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results['Lasso'] = round(error_percent, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebe-se que Lasso tem menor erro que o linear, portanto iremos adotar o Lasso para o restante dos experimentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terceiro experimento: Lasso + fazer transformação de log para features com skewness (assimetria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justificativa para realizar uma feature engineering a mais no modelo\n",
    "\n",
    "\n",
    "Além do trabalho realizado pelo Professor [Fabio J. Ayres](https://github.com/FabioAyresInsper) no *dataset* Ames, realizamos a seguinte feature engineering:\n",
    "\n",
    "- **Transformação de log para features com skewness (assimetria)**, já que ela é conhecida por fazer uma feature que tem distribuição assimétrica ter uma distribuição mais próxima da normal, o que é desejável para modelos de regressão linear. Optamos por realizá-la, pois no `02_analysis_and_preprocessing.ipynb` é possível observar um comportamente de assimetria no histogramas de algumas features. Como exemplo, vide o histograma da feature `Lot.Area`.\n",
    "\n",
    "Além disso, a transformação de log atenua o impacto de outliers, uma vez que \"espreme\" os valores extremamente altos em direção aos valores médios. Isso pode ser útil para reduzir a influência de outliers nos resultados. Isso pode ser observado em alguns histogramas, como o da feature `Enclosed.Porch`, em que a assimetria se dá principalmente por conta de um *outlier*.\n",
    "\n",
    "**DISCLAIMER: Vamos aplicar um threshold e realizar a transformação de log somente nas features com maior assimetria. Para isso, usaremos um threshold de 3. Não existe um indício claro que esse feature engineering trará resultado positivo, contudo certamente não trará nenhum impacto negativo.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos testar *skewness* para todas as colunas e adquire o index daquelas que possuem *skewness* > 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lot.Frontage        1.374507\n",
       "Lot.Area           13.935570\n",
       "Mas.Vnr.Area        2.584621\n",
       "BsmtFin.SF.1        1.013526\n",
       "BsmtFin.SF.2        4.222772\n",
       "Bsmt.Unf.SF         0.955611\n",
       "Total.Bsmt.SF       0.729935\n",
       "X1st.Flr.SF         1.263409\n",
       "X2nd.Flr.SF         0.842831\n",
       "Low.Qual.Fin.SF    11.186456\n",
       "Gr.Liv.Area         1.096900\n",
       "Bsmt.Full.Bath      0.614981\n",
       "Bsmt.Half.Bath      3.940715\n",
       "Full.Bath           0.159638\n",
       "Half.Bath           0.686145\n",
       "Bedroom.AbvGr       0.408400\n",
       "Kitchen.AbvGr       4.018729\n",
       "TotRms.AbvGrd       0.770448\n",
       "Fireplaces          0.730059\n",
       "Garage.Cars        -0.179943\n",
       "Garage.Area         0.264373\n",
       "Wood.Deck.SF        1.974402\n",
       "Open.Porch.SF       2.676164\n",
       "Enclosed.Porch      4.144894\n",
       "X3Ssn.Porch        11.380044\n",
       "Screen.Porch        3.984604\n",
       "Pool.Area          18.402387\n",
       "Misc.Val           23.239878\n",
       "Mo.Sold             0.210787\n",
       "Yr.Sold             0.156685\n",
       "Garage.Age          0.639825\n",
       "Remod.Age           0.432224\n",
       "House.Age           0.570505\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "skewness = Xtrain.select_dtypes('float64').apply(skew)\n",
    "\n",
    "skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Lot.Area', 'BsmtFin.SF.2', 'Low.Qual.Fin.SF', 'Bsmt.Half.Bath',\n",
       "       'Kitchen.AbvGr', 'Enclosed.Porch', 'X3Ssn.Porch', 'Screen.Porch',\n",
       "       'Pool.Area', 'Misc.Val'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skewness = skewness[abs(skewness) > 3]\n",
    "\n",
    "skew_features = Xtrain[skewness.index]\n",
    "\n",
    "skew_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_tf(feature):\n",
    "    return np.log1p(feature)\n",
    "\n",
    "Xtrain_skew = Xtrain.copy()\n",
    "Xtest_skew = Xtest.copy()\n",
    "\n",
    "Xtrain_skew[skew_features.columns] = Xtrain_skew[skew_features.columns].apply(log_tf)\n",
    "Xtest_skew[skew_features.columns] = Xtest_skew[skew_features.columns].apply(log_tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.fit(Xtrain_skew)\n",
    "\n",
    "Xtrain_scaled = col.transform(Xtrain_skew)\n",
    "Xtest_scaled = col.transform(Xtest_skew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "grid_search.fit(Xtrain_scaled, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(-grid_search.best_score_)\n",
    "error_percent = 100 * (10**rmse - 1)\n",
    "print(f'Average error is {error_percent:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results['Lasso+Skew'] = round(error_percent, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos perceber que a transformação de log para features com *skewness* > 3 trouxe um resultado positivo para o modelo. Portanto, iremos adotar isso para o restante dos experimentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decidimos testar abaixo o Elastic Net, pois ele é uma combinação entre Lasso e Ridge, já que o Lasso é um modelo que já testamos e trouxe bons resultados. Portanto, acreditamos que o Elastic Net trará resultados melhores que somente o Lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quarto experimento: Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Elastic Net é um modelo de regressão linear que combina duas técnicas de regularização: a regularização L1 (Lasso) e a regularização L2 (Ridge). É usado para lidar com problemas de regressão, semelhante à regressão linear, mas com a adição dessas penalizações, o que torna o modelo mais robusto e ajuda a evitar problemas de overfitting. O Elastic Net é útil quando se lida com conjuntos de dados que têm muitas características (alta dimensionalidade) e algumas delas são altamente correlacionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "grid = {\n",
    "    'alpha': np.logspace(-8, -3, 10),\n",
    "    'l1_ratio': np.linspace(0.01, 1, 50),\n",
    "}\n",
    "\n",
    "elastic = ElasticNet(random_state=RANDOM_SEED)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    elastic,\n",
    "    grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    return_train_score=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "grid_search.fit(Xtrain_scaled, ytrain) # This takes the Xtrain_scaled with the skewness transformation\n",
    "\n",
    "print(f'Best parameters: {grid_search.best_params_}')\n",
    "print(f'Best score: {grid_search.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(-grid_search.best_score_)\n",
    "error_percent = 100 * (10**rmse - 1)\n",
    "print(f'Average error is {error_percent:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results['Elastic Net'] = round(error_percent, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação entre os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('| Model | Average Error |\\n| --- | --- |\\n')\n",
    "for model, error in model_results.items():\n",
    "    print(f'| {model} | {error} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Considerando todas os experimentos realizados, o Elastic Net foi o modelo com menor erro percentual.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rodando o modelo Elastic Net no dataset de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = grid_search.best_estimator_.predict(Xtest_scaled)\n",
    "rmse = np.sqrt(mean_squared_error(ytest, val))\n",
    "error_percent = 100 * (10**rmse - 1)\n",
    "print(f'Average error is {error_percent:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação: baseline vs. melhor modelo (Elastic Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_baseline = 15.11\n",
    "print(f\"O delta de erro entre eles é: {error_baseline - model_results['Elastic Net']}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quais as consequências do desempenho do modelo final para a aplicação de negócios?\n",
    "\n",
    "O modelo final, Elastic Net, tem um erro percentual de aproximadamente 15%. O impacto deste percentual não é irrelevante, dado que pode corresponder ao valor de comissão do negócio de venda do imóvel, portanto, para uma aplicação em nível de vida real, é importante que o modelo seja melhorado, ou seja usado com cautela máxima, com o cliente havendo sido informado sobre a margem de erro previamente (algo como uma \"estimativa grosseira\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quais features são mais importantes na determinação do preço do imóvel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "rfecv = RFECV(\n",
    "    grid_search.best_estimator_,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    ")\n",
    "\n",
    "rfecv.fit(Xtrain_scaled, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Optimal number of features: {rfecv.n_features_}')\n",
    "\n",
    "print(f'Selected features: {Xtrain.columns[rfecv.support_]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Feature ranking (importance): {rfecv.ranking_}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ames",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbd4e51fa3f3bf2a2317a230e3ac8d5fc66f1a44e44c3383f6bf669b9d199507"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
